{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu2S86VhS-8t"
      },
      "source": [
        "# GREMLIN_TF v2.1.BETA.1\n",
        "GREMLIN implemented in tensorflow\n",
        "\n",
        "### Change log:\n",
        "*   19Apr2019\n",
        " - added option to ignore gaps (now the default)\n",
        " - added option to initialize v and w from input\n",
        " - added function to score sequences (for design, ranking-mutations/homologys)\n",
        "*   02Apr2019\n",
        " - fixed a few hard-coded values, to allow GREMLIN to work with any alphabet (binary, protein, rna etc)\n",
        "*   22Jan2019\n",
        " - moving [GREMLIN_TF_simple](https://colab.research.google.com/github/sokrypton/GREMLIN_CPP/blob/master/GREMLIN_TF_simple.ipynb) to a seperate notebook\n",
        "*   19Jan2019\n",
        " - in the past we found that optimizing V first, required less iterations for convergence. Since V can be computed exactly (assuming no W), we replace this first optimization step with a simple V initialization.\n",
        " - a few variables were renamed to be consistent with the c++ version\n",
        "*   16Jan2019\n",
        " - updated how indices are handled (for easier/cleaner parsing)\n",
        " - minor speed up in how we symmetrize and zero the diagional of W\n",
        "*   15Jan2019\n",
        " - LBFGS optimizer replaced with a modified version of the ADAM optimizer\n",
        " - Added option for stochastic gradient descent (via batch_size)\n",
        "  \n",
        "### Method:\n",
        "GREMLIN takes a multiple sequence alignment (MSA) and returns a Markov Random Field (MRF). The MRF consists of a one-body term (V) that encodes conservation, and a two-body term (W) that encodes co-evolution.\n",
        "\n",
        "For more details about the method see:\n",
        "[Google slides](https://docs.google.com/presentation/d/1aooxoksosSv7CWs9-ktqhUjyXR3wrgbG5a6PCr92od4/) and accompanying [Google colab](https://colab.research.google.com/drive/17RJcExuyifnd7ShTcsZGh6mBpWq0-s60)\n",
        "\n",
        "See [GREMLIN_TF_simple](https://colab.research.google.com/github/sokrypton/GREMLIN_CPP/blob/master/GREMLIN_TF_simple.ipynb) for a stripped down version of this code (with no funky gap removal, sequence weight, etc). This is intented for educational purpose,  and could also be very useful for anyone trying to modify or improve the algorithm!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM3wyYU5SwYn"
      },
      "source": [
        "# ------------------------------------------------------------------\n",
        "# \"THE BEERWARE LICENSE\" (Revision 42)\n",
        "# ------------------------------------------------------------------\n",
        "# <so@g.harvard.edu> and <pkk382@g.harvard.edu> wrote this code.\n",
        "# As long as you retain this notice, you can do whatever you want\n",
        "# with this stuff. If we meet someday, and you think this stuff\n",
        "# is worth it, you can buy us a beer in return.\n",
        "# --Sergey Ovchinnikov and Peter Koo\n",
        "# ------------------------------------------------------------------\n",
        "# The original MATLAB code for GREMLIN was written by Hetu Kamisetty\n",
        "# ------------------------------------------------------------------"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF37ECjqaOt-",
        "outputId": "2f4dfce7-bc17-4a76-db02-349dd95bb9f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLUvPVyxb7bo"
      },
      "source": [
        "## External libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJpLM_tJfrY"
      },
      "source": [
        "# IMPORTANT, only tested using PYTHON 3!\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "import matplotlib.pylab as plt\n",
        "from scipy import stats\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.special import logsumexp\n",
        "import pandas as pd"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Yp7bPRmvwU"
      },
      "source": [
        "## Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3c7KURqmugY"
      },
      "source": [
        "################\n",
        "# note: if you are modifying the alphabet\n",
        "# make sure last character is \"-\" (gap)\n",
        "################\n",
        "alphabet = \"ARNDCQEGHILKMFPSTWYV-\"\n",
        "states = len(alphabet)\n",
        "\n",
        "# map amino acids to integers (A->0, R->1, etc)\n",
        "a2n = dict((a,n) for n,a in enumerate(alphabet))\n",
        "aa2int = lambda x: a2n.get(x,a2n['-'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX6GXKV3I2pm"
      },
      "source": [
        "## Parse MSA (Multiple Seq Alignment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0Bne59SUIu"
      },
      "source": [
        "# from fasta\n",
        "def parse_fasta(filename):\n",
        "  '''function to parse fasta'''\n",
        "  header = []\n",
        "  sequence = []\n",
        "  lines = open(filename, \"r\")\n",
        "  for line in lines:\n",
        "    line = line.rstrip()\n",
        "    if line[0] == \">\":\n",
        "      header.append(line[1:])\n",
        "      sequence.append([])\n",
        "    else:\n",
        "      sequence[-1].append(line)\n",
        "  lines.close()\n",
        "  sequence = [''.join(seq) for seq in sequence]\n",
        "  return np.array(header), np.array(sequence)\n",
        "\n",
        "def filt_gaps(msa, gap_cutoff=0.5):\n",
        "  '''filters alignment to remove gappy positions'''\n",
        "  frac_gaps = np.mean((msa == states-1).astype(float),0)\n",
        "  non_gaps = np.where(frac_gaps < gap_cutoff)[0]\n",
        "  return msa[:,non_gaps], non_gaps\n",
        "\n",
        "def get_eff(msa, eff_cutoff=0.8):\n",
        "  '''compute effective weight for each sequence'''\n",
        "  msa_sm = 1.0 - squareform(pdist(msa,\"hamming\"))\n",
        "  msa_w = (msa_sm >= eff_cutoff).astype(float)\n",
        "  msa_w = 1.0/np.sum(msa_w,-1)\n",
        "  return msa_w\n",
        "\n",
        "def str2int(x):\n",
        "  '''convert a list of strings into list of integers'''\n",
        "  # Example: [\"ACD\",\"EFG\"] -> [[0,4,3], [6,13,7]]\n",
        "  if x.dtype.type is np.str_:\n",
        "    if x.ndim == 0: return np.array([aa2int(aa) for aa in x])\n",
        "    else: return np.array([[aa2int(aa) for aa in seq] for seq in x])\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "def split_train_test(seqs, frac_test=0.1):\n",
        "  # shuffle data\n",
        "  x = np.copy(seqs)\n",
        "  np.random.shuffle(x[1:])\n",
        "\n",
        "  # fraction of data used for testing\n",
        "  split = int(len(x) * (1.0-frac_test))\n",
        "\n",
        "  # split training/test datasets\n",
        "  return x[:split], x[split:]\n",
        "\n",
        "def mk_msa(seqs, gap_cutoff=0.5, eff_cutoff=0.8):\n",
        "  '''converts list of sequences to MSA (Multiple Sequence Alignment)'''\n",
        "  # =============================================================================\n",
        "  # The function takes a list of sequences (strings) and returns a (dict)ionary\n",
        "  # containing the following:\n",
        "  # =============================================================================\n",
        "  # BEFORE GAP REMOVAL\n",
        "  # -----------------------------------------------------------------------------\n",
        "  # msa_ori   msa\n",
        "  # ncol_ori  number of columns\n",
        "  # -----------------------------------------------------------------------------\n",
        "  # AFTER GAP REMOVAL\n",
        "  # By default, columns with â‰¥ 50% gaps are removed. This makes things a\n",
        "  # little complicated, as we need to keep track of which positions were removed.\n",
        "  # -----------------------------------------------------------------------------\n",
        "  # msa       msa\n",
        "  # ncol      number of columns\n",
        "  # v_idx     index of positions kept\n",
        "  # -----------------------------------------------------------------------------\n",
        "  # weights   weight for each sequence (based on sequence identity)\n",
        "  # nrow      number of rows (sequences)\n",
        "  # neff      number of effective sequences sum(weights)\n",
        "  # =============================================================================\n",
        "\n",
        "  msa_ori = str2int(seqs)\n",
        "\n",
        "  # remove positions with more than > 50% gaps\n",
        "  msa, v_idx = filt_gaps(msa_ori)\n",
        "\n",
        "  # compute effective weight for each sequence\n",
        "  msa_weights = get_eff(msa, eff_cutoff)\n",
        "\n",
        "  return {\"msa_ori\":msa_ori,\n",
        "          \"msa\":msa,\n",
        "          \"weights\":msa_weights,\n",
        "          \"neff\":np.sum(msa_weights),\n",
        "          \"v_idx\":v_idx,\n",
        "          \"nrow\":msa.shape[0],\n",
        "          \"ncol\":msa.shape[1],\n",
        "          \"ncol_ori\":msa_ori.shape[1]}"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky6gk-HlFyi"
      },
      "source": [
        "## GREMLIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx14M7Tvu-Ct"
      },
      "source": [
        "# optimizer\n",
        "def opt_adam(loss, name, var_list=None, lr=1.0, b1=0.9, b2=0.999, b_fix=False):\n",
        "  # adam optimizer\n",
        "  # Note: this is a modified version of adam optimizer. More specifically, we replace \"vt\"\n",
        "  # with sum(g*g) instead of (g*g). Furthmore, we find that disabling the bias correction\n",
        "  # (b_fix=False) speeds up convergence for our case.\n",
        "\n",
        "  if var_list is None: var_list = tf.trainable_variables()\n",
        "  gradients = tf.gradients(loss,var_list)\n",
        "  if b_fix: t = tf.Variable(0.0,\"t\")\n",
        "  opt = []\n",
        "  for n,(x,g) in enumerate(zip(var_list,gradients)):\n",
        "    if g is not None:\n",
        "      ini = dict(initializer=tf.zeros_initializer,trainable=False)\n",
        "      mt = tf.get_variable(name+\"_mt_\"+str(n),shape=list(x.shape), **ini)\n",
        "      vt = tf.get_variable(name+\"_vt_\"+str(n),shape=[], **ini)\n",
        "\n",
        "      mt_tmp = b1*mt+(1-b1)*g\n",
        "      vt_tmp = b2*vt+(1-b2)*tf.reduce_sum(tf.square(g))\n",
        "      lr_tmp = lr/(tf.sqrt(vt_tmp) + 1e-8)\n",
        "\n",
        "      if b_fix: lr_tmp = lr_tmp * tf.sqrt(1-tf.pow(b2,t))/(1-tf.pow(b1,t))\n",
        "\n",
        "      opt.append(x.assign_add(-lr_tmp * mt_tmp))\n",
        "      opt.append(vt.assign(vt_tmp))\n",
        "      opt.append(mt.assign(mt_tmp))\n",
        "\n",
        "  if b_fix: opt.append(t.assign_add(1.0))\n",
        "  return(tf.group(opt))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqYqlJAXVI9N"
      },
      "source": [
        "def GREMLIN(msa,\n",
        "            opt_iter=100,\n",
        "            opt_rate=1.0,\n",
        "            batch_size=None,\n",
        "            lam_v=0.01,\n",
        "            lam_w=0.01,\n",
        "            scale_lam_w=True,\n",
        "            v=None,\n",
        "            w=None,\n",
        "            ignore_gap=True):\n",
        "\n",
        "  '''fit params of MRF (Markov Random Field) given MSA (multiple sequence alignment)'''\n",
        "  # ==========================================================================\n",
        "  # this function takes a MSA (dict)ionary, from mk_msa() and returns a MRF\n",
        "  # (dict)ionary containing the following:\n",
        "  # ==========================================================================\n",
        "  # len       full length\n",
        "  # v_idx     index of positions (mapping back to full length)\n",
        "  # v         2-body term\n",
        "  # w         2-body term\n",
        "  # ==========================================================================\n",
        "  # WARNING: The mrf is over the msa after gap removal. \"v_idx\" and \"len\" are\n",
        "  # important for mapping the MRF back to the original MSA.\n",
        "  # ==========================================================================\n",
        "\n",
        "  ########################################\n",
        "  # SETUP COMPUTE GRAPH\n",
        "  ########################################\n",
        "  # reset tensorflow graph\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # length of sequence\n",
        "  ncol = msa[\"ncol\"]\n",
        "\n",
        "  # input msa (multiple sequence alignment)\n",
        "  MSA = tf.placeholder(tf.int32,shape=(None,ncol),name=\"msa\")\n",
        "\n",
        "  # input msa weights\n",
        "  MSA_weights = tf.placeholder(tf.float32, shape=(None,), name=\"msa_weights\")\n",
        "\n",
        "  # one-hot encode msa\n",
        "  OH_MSA = tf.one_hot(MSA,states)\n",
        "\n",
        "  if ignore_gap:\n",
        "    ncat = states - 1\n",
        "    NO_GAP = 1.0 - OH_MSA[...,-1]\n",
        "    OH_MSA = OH_MSA[...,:ncat]\n",
        "\n",
        "  else:\n",
        "    ncat = states\n",
        "\n",
        "  ########################################\n",
        "  # V: 1-body-term of the MRF\n",
        "  ########################################\n",
        "  V = tf.get_variable(name=\"V\",\n",
        "                          shape=[ncol,ncat],\n",
        "                          initializer=tf.zeros_initializer)\n",
        "\n",
        "  ########################################\n",
        "  # W: 2-body-term of the MRF\n",
        "  ########################################\n",
        "  W_tmp = tf.get_variable(name=\"W\",\n",
        "                          shape=[ncol,ncat,ncol,ncat],\n",
        "                          initializer=tf.zeros_initializer)\n",
        "\n",
        "  # symmetrize W\n",
        "  W = W_tmp + tf.transpose(W_tmp,[2,3,0,1])\n",
        "\n",
        "  # set diagonal to zero\n",
        "  W = W * (1-np.eye(ncol))[:,None,:,None]\n",
        "\n",
        "  ########################################\n",
        "  # Pseudo-Log-Likelihood\n",
        "  ########################################\n",
        "  # V + W\n",
        "  VW = V + tf.tensordot(OH_MSA,W,2)\n",
        "\n",
        "  # hamiltonian\n",
        "  H = tf.reduce_sum(OH_MSA*VW,-1)\n",
        "\n",
        "  # local Z (parition function)\n",
        "  Z = tf.reduce_logsumexp(VW,-1)\n",
        "\n",
        "  PLL = H - Z\n",
        "  if ignore_gap:\n",
        "    PLL = PLL * NO_GAP\n",
        "\n",
        "  PLL = tf.reduce_sum(PLL,-1)\n",
        "  PLL = tf.reduce_sum(MSA_weights * PLL)/tf.reduce_sum(MSA_weights)\n",
        "\n",
        "  ########################################\n",
        "  # Regularization\n",
        "  ########################################\n",
        "  L2 = lambda x: tf.reduce_sum(tf.square(x))\n",
        "  L2_V = lam_v * L2(V)\n",
        "  L2_W = lam_w * L2(W) * 0.5\n",
        "\n",
        "  if scale_lam_w:\n",
        "    L2_W = L2_W * (ncol-1) * (states-1)\n",
        "\n",
        "  ########################################\n",
        "  # Loss Function\n",
        "  ########################################\n",
        "  # loss function to minimize\n",
        "  loss = -PLL + (L2_V + L2_W) / msa[\"neff\"]\n",
        "\n",
        "  # optimizer\n",
        "  opt = opt_adam(loss,\"adam\",lr=opt_rate)\n",
        "\n",
        "  ########################################\n",
        "  # Input Generator\n",
        "  ########################################\n",
        "  all_idx = np.arange(msa[\"nrow\"])\n",
        "  def feed(feed_all=False):\n",
        "    if batch_size is None or feed_all:\n",
        "      return {MSA:msa[\"msa\"], MSA_weights:msa[\"weights\"]}\n",
        "    else:\n",
        "      batch_idx = np.random.choice(all_idx,size=batch_size)\n",
        "      return {MSA:msa[\"msa\"][batch_idx], MSA_weights:msa[\"weights\"][batch_idx]}\n",
        "\n",
        "  ########################################\n",
        "  # OPTIMIZE\n",
        "  ########################################\n",
        "  with tf.Session() as sess:\n",
        "\n",
        "    # initialize variables V and W\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # initialize V\n",
        "    if v is None:\n",
        "      oh_msa = np.eye(states)[msa[\"msa\"]]\n",
        "      if ignore_gap: oh_msa = oh_msa[...,:-1]\n",
        "\n",
        "      pseudo_count = 0.01 * np.log(msa[\"neff\"])\n",
        "      f_v = np.einsum(\"nla,n->la\",oh_msa,msa[\"weights\"])\n",
        "      V_ini = np.log(f_v + pseudo_count)\n",
        "      if lam_v > 0:\n",
        "        V_ini = V_ini - np.mean(V_ini,axis=-1,keepdims=True)\n",
        "      sess.run(V.assign(V_ini))\n",
        "\n",
        "    else:\n",
        "      sess.run(V.assign(v))\n",
        "\n",
        "    # initialize W\n",
        "    if w is not None:\n",
        "      sess.run(W_tmp.assign(w * 0.5))\n",
        "\n",
        "    # compute loss across all data\n",
        "    get_loss = lambda: np.round(sess.run(loss,feed(True)) * msa[\"neff\"],2)\n",
        "\n",
        "    print(\"starting\",get_loss())\n",
        "    for i in range(opt_iter):\n",
        "      sess.run(opt,feed())\n",
        "      if (i+1) % int(opt_iter/10) == 0:\n",
        "        print(\"iter\",(i+1),get_loss())\n",
        "\n",
        "    # save the V and W parameters of the MRF\n",
        "    V_ = sess.run(V)\n",
        "    W_ = sess.run(W)\n",
        "\n",
        "  ########################################\n",
        "  # return MRF\n",
        "  ########################################\n",
        "  no_gap_states = states - 1\n",
        "  mrf = {\"v\": V_[:,:no_gap_states],\n",
        "         \"w\": W_[:,:no_gap_states,:,:no_gap_states],\n",
        "         \"v_idx\": msa[\"v_idx\"],\n",
        "         \"len\": msa[\"ncol_ori\"]}\n",
        "\n",
        "  return mrf"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mppg0JLtP25z"
      },
      "source": [
        "## EXAMPLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnigmLmAlyWv"
      },
      "source": [
        "# download example fasta MSA\n",
        "!wget -q -nc https://gremlin2.bakerlab.org/db/PDB_EXP/fasta/4FAZA.fas"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osaZwTSMOicF"
      },
      "source": [
        "# ==========================================================================\n",
        "# PREP MSA\n",
        "# ==========================================================================\n",
        "# parse fasta\n",
        "headers, seqs = parse_fasta(\"/content/drive/MyDrive/GREMLIN/CaM/CaM_f1864.fasta\")\n",
        "\n",
        "train_seqs, test_seqs = split_train_test(seqs, frac_test=0.1)\n",
        "\n",
        "# process input training sequences\n",
        "msa = mk_msa(train_seqs, gap_cutoff=0.3, eff_cutoff=0.8)\n",
        "# gap_cutoff=0.5 (positions with â‰¥ 50% gaps are removed)\n",
        "# eff_cutoff=0.8 (sequences that share â‰¥ 80% sequence identity\n",
        "# are considered \"effectively\" a single sequence)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoBRuqmVVrbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c051dc23-306c-482f-d257-bc567e049912"
      },
      "source": [
        "%%time\n",
        "# ==========================================================================\n",
        "# RUN GREMLIN\n",
        "# ==========================================================================\n",
        "mrf = GREMLIN(msa,lam_w=0.01)\n",
        "\n",
        "# NOTE: lam_v (for one-body term) lam_w (for two-body term) can be used to regularize the model\n",
        "#\n",
        "# for contact prediction we find lam_w = 0.01 to be most optimial\n",
        "# (even though it's technically overfitting on the data!)\n",
        "# the overfitting is partly corrected by APC\n",
        "#\n",
        "# for design/scoring you may want to bump the lam_w to a higher value!\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting 3755691.95\n",
            "iter 10 3101065.91\n",
            "iter 20 2802758.78\n",
            "iter 30 2635684.0\n",
            "iter 40 2528304.89\n",
            "iter 50 2456052.02\n",
            "iter 60 2405385.71\n",
            "iter 70 2368718.3\n",
            "iter 80 2341431.7\n",
            "iter 90 2320794.6\n",
            "iter 100 2304966.94\n",
            "CPU times: user 11.7 s, sys: 641 ms, total: 12.4 s\n",
            "Wall time: 20.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPL-5atH4iVZ"
      },
      "source": [
        "## Use the MRF model to score \"new\" sequences\n",
        "The source of \"new\" sequences maybe:\n",
        " - Test sequences (to check for overfitting)\n",
        " - Mutant sequences (to predict effects of mutations)\n",
        " - Newly sequenced genomes (to test fit to model, for annotation and homology search)\n",
        "\n",
        "Note, high score means better fit to model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANAjrL5E-k-Z"
      },
      "source": [
        "###############\n",
        "## FUNCTIONS\n",
        "###############\n",
        "def score(mrf, x, recompute_z=False):\n",
        "  x = str2int(x)\n",
        "\n",
        "  # if length of sequence != length of model\n",
        "  if x.shape[-1] != len(mrf[\"v_idx\"]):\n",
        "    x = x[...,mrf[\"v_idx\"]]\n",
        "\n",
        "  # one hot encode\n",
        "  x = np.eye(states)[x]\n",
        "\n",
        "  # get non-gap positions\n",
        "  no_gap = 1.0 - x[...,-1]\n",
        "\n",
        "  # remove gap from one-hot-encoding\n",
        "  x = x[...,:-1]\n",
        "\n",
        "  # compute score\n",
        "  vw = mrf[\"v\"] + np.tensordot(x,mrf[\"w\"],2)\n",
        "\n",
        "  # ============================================================================================\n",
        "  # Note, Z (the partition function) is a constant. In GREMLIN, V, W & Z are estimated using all\n",
        "  # the original weighted input sequence(s). It is NOT recommended to recalculate Z with a\n",
        "  # different set of sequences. Given the common ERROR of recomputing Z, we include the option\n",
        "  # to do so, for comparison.\n",
        "  # ============================================================================================\n",
        "  h = np.sum(np.multiply(x,vw),axis=-1)\n",
        "  if recompute_z:\n",
        "    z = logsumexp(vw, axis=-1)\n",
        "    return np.sum((h-z), axis=-1)\n",
        "  else:\n",
        "    return np.sum(h, axis=-1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8hhfv2I9Jc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cb7506-e17b-4655-c8f8-311e18540399"
      },
      "source": [
        "# provide a single sequence\n",
        "print(seqs[0])\n",
        "score(mrf,seqs[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTIDFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREANIDGDGQVNYEEFVQMMTAK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "746.5075022662677"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aU2hoUY9eQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5203685-503b-4311-ca09-ba817f2ff737"
      },
      "source": [
        "# provide multiple sequences\n",
        "print(seqs[0:3])\n",
        "score(mrf,seqs[0:3])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTIDFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREANIDGDGQVNYEEFVQMMTAK'\n",
            " 'ADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELRDMINEVDTDGNGTIDFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGFISAAELRHVMTNLGEKLTDEEVDEMIREADTDNDGQINYDEFVKMMTSK'\n",
            " 'ADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTIDFPEFLTMMAKKMKDSDSEDELKEAFKVFDKDGNGFISAAELRHVMTNLGEKLTDEEVDEMIREADTDGDGQVNYEEFVQMMTSK']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([746.50750227, 724.55091266, 727.19267845])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZOM09Ut9nSE"
      },
      "source": [
        "# provide all the sequences\n",
        "train_scos = score(mrf, train_seqs)\n",
        "test_scos = score(mrf, test_seqs)\n",
        "plt.hist(train_scos,bins=10,alpha=0.5,density=True,label=\"train\")\n",
        "plt.hist(test_scos,bins=10,alpha=0.5,density=True,label=\"test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCrfC2Um4xww"
      },
      "source": [
        "## Explore the contact map\n",
        "### Contact prediction:\n",
        "\n",
        "For contact prediction, the W matrix is reduced from LxLx20x20 to LxL matrix (by taking the L2norm for each of the 20x20). In the code below, you can access this as mtx[\"raw\"]. Further correction (average product correction) is then performed to the mtx[\"raw\"] to remove the effects of entropy, mtx[\"apc\"]. The relative ranking of mtx[\"apc\"] is used to assess importance. When there are enough effective sequences (>1000), we find that the top 1.0L contacts are ~90% accurate! When the number of effective sequences is lower, NN can help clean noise and fill in missing contacts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMxp7up_P1_q"
      },
      "source": [
        "###############\n",
        "## FUNCTIONS\n",
        "###############\n",
        "def normalize(x):\n",
        "  x = stats.boxcox(x - np.amin(x) + 1.0)[0]\n",
        "  x_mean = np.mean(x)\n",
        "  x_std = np.std(x)\n",
        "  return((x-x_mean)/x_std)\n",
        "\n",
        "def get_mtx(mrf):\n",
        "  '''convert MRF (Markov Random Field) to MTX (Matrix or Contact-map)'''\n",
        "\n",
        "  # raw (l2norm of each 20x20 matrix)\n",
        "  raw_sq = np.sqrt(np.sum(np.square(mrf[\"w\"]),(1,3)))\n",
        "  raw = squareform(raw_sq, checks=False)\n",
        "\n",
        "  # apc (average product correction)\n",
        "  ap_sq = np.sum(raw_sq,0,keepdims=True) * np.sum(raw_sq,1,keepdims=True)/np.sum(raw_sq)\n",
        "  apc = squareform(raw_sq - ap_sq, checks=False)\n",
        "\n",
        "  i, j = np.triu_indices_from(raw_sq,k=1)\n",
        "  mtx = {\n",
        "         \"i\": mrf[\"v_idx\"][i],\n",
        "         \"j\": mrf[\"v_idx\"][j],\n",
        "         \"raw\": raw,\n",
        "         \"apc\": apc,\n",
        "         \"zscore\": normalize(apc),\n",
        "         \"len\": mrf[\"len\"]\n",
        "  }\n",
        "  return mtx\n",
        "\n",
        "def plot_mtx(mtx):\n",
        "  '''plot the mtx'''\n",
        "  plt.figure(figsize=(15,5))\n",
        "  for n, key in enumerate([\"raw\",\"apc\",\"zscore\"]):\n",
        "\n",
        "    # create empty mtx\n",
        "    m = np.ones((mtx[\"len\"],mtx[\"len\"])) * np.nan\n",
        "\n",
        "    # populate\n",
        "    m[mtx[\"i\"],mtx[\"j\"]] = mtx[key]\n",
        "    m[mtx[\"j\"],mtx[\"i\"]] = m[mtx[\"i\"],mtx[\"j\"]]\n",
        "\n",
        "    #plot\n",
        "    plt.subplot(1,3,n+1)\n",
        "    plt.title(key)\n",
        "    if key == \"zscore\": plt.imshow(m, cmap='Blues', vmin=1, vmax=3)\n",
        "    else: plt.imshow(m, cmap='Blues')\n",
        "    plt.grid(False)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSleviAVPJ36"
      },
      "source": [
        "mtx = get_mtx(mrf)\n",
        "plot_mtx(mtx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWaTHLTH5rGw"
      },
      "source": [
        "## Look at top co-evolving residue pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A2yeOJ8uPNM"
      },
      "source": [
        "######################################################################################\n",
        "# WARNING - WARNING - WARNING\n",
        "######################################################################################\n",
        "# - the index starts at 0\n",
        "# - the \"first\" position is 0\n",
        "# - in bioinformatics, the first position of a sequence is often \"1\"\n",
        "#   for this index use i_aa and j_aa!\n",
        "\n",
        "# adding amino acid to index+1\n",
        "seq = seqs[0]\n",
        "mtx[\"i_aa\"] = [f\"{seq[i]}_{i+1}\" for i in mtx[\"i\"]]\n",
        "mtx[\"j_aa\"] = [f\"{seq[j]}_{j+1}\" for j in mtx[\"j\"]]\n",
        "\n",
        "# load mtx into pandas dataframe\n",
        "pd_mtx = pd.DataFrame(mtx,columns=[\"i\",\"j\",\"raw\",\"apc\",\"zscore\",\"i_aa\",\"j_aa\"])\n",
        "\n",
        "# get contacts with sequence seperation > 5, sort\n",
        "top = pd_mtx.loc[pd_mtx['j'] - pd_mtx['i'] > 5].sort_values(\"apc\",ascending=False)\n",
        "\n",
        "# show top 10\n",
        "top.head(500)\n",
        "pd_mtx.to_csv(\"dhfr_colabmsa_mtx.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqG93dC12CKx"
      },
      "source": [
        "## Explore the MRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6BsheyNx3ID"
      },
      "source": [
        "###############\n",
        "## FUNCTIONS\n",
        "###############\n",
        "def plot_pssm(v):\n",
        "  mx = np.abs(v[np.where(v is not np.nan)]).max()\n",
        "  # plot\n",
        "  plt.figure(figsize=(v.shape[0]/4,v.shape[1]/4))\n",
        "  plt.imshow(-v.T,cmap='bwr',vmin=-mx,vmax=mx)\n",
        "  plt.yticks(np.arange(0,states-1))\n",
        "  plt.grid(False)\n",
        "  plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: alphabet[x]))\n",
        "  plt.show()\n",
        "\n",
        "def plot_v(mrf):\n",
        "  # prep\n",
        "  v = np.ones((mrf[\"len\"],mrf[\"v\"].shape[1])) * np.nan\n",
        "  v[mrf[\"v_idx\"]] = mrf[\"v\"]\n",
        "  plot_pssm(v)\n",
        "\n",
        "def plot_w(mrf,i,j):\n",
        "  i_idx = np.where(mrf[\"v_idx\"] == i)[0][0]\n",
        "  j_idx = np.where(mrf[\"v_idx\"] == j)[0][0]\n",
        "  w = mrf[\"w\"][i_idx,:,j_idx,:]\n",
        "  mx = np.abs(w).max()\n",
        "\n",
        "  # plot\n",
        "  plt.figure(figsize=(w.shape[0]/4,w.shape[1]/4))\n",
        "  plt.imshow(-w,cmap='bwr',vmin=-mx,vmax=mx)\n",
        "  plt.xticks(np.arange(w.shape[0]))\n",
        "  plt.yticks(np.arange(w.shape[1]))\n",
        "  plt.grid(False)\n",
        "  plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: alphabet[x]))\n",
        "  plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x,y: alphabet[x]))\n",
        "  plt.title(f\"coupling matrix for {i} and {j}\")\n",
        "  plt.show()\n",
        "\n",
        "  # Assuming you've already created a DataFrame called pd_mtx with columns:\n",
        "#   \"i\", \"j\", \"raw\", \"apc\", \"zscore\", \"i_aa\", \"j_aa\"\n",
        "# and you've sorted it by \"apc\" in descending order (or whichever score you prefer)\n",
        "\n",
        "# Example filtering: only consider residue pairs with separation > 5\n",
        "top = pd_mtx.loc[pd_mtx['j'] - pd_mtx['i'] > 5].sort_values(\"apc\", ascending=False)\n",
        "\n",
        "# Extract the top 5 strongest couplings\n",
        "top_10 = top.head(10)\n",
        "print(top_10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaslLXvXbFcw"
      },
      "source": [
        "plot_v(mrf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEncuXvWbCex"
      },
      "source": [
        "# Loop through each pair and call plot_w(mrf, i, j)\n",
        "for idx, row in top_10.iterrows():\n",
        "    i = int(row['i'])  # residue i\n",
        "    j = int(row['j'])  # residue j\n",
        "    print(f\"Plotting coupling matrix for residues {i} and {j} with APC score {row['apc']}\")\n",
        "    plot_w(mrf, i, j)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf8Qbkwfr4ke"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "msa = parse_fasta(\"/content/drive/MyDrive/GREMLIN/ras_454e0.fasta\")  # Replace with the correct file path\n",
        "\n",
        "print(type(msa))\n",
        "print(msa[:5])  # Print first 5 entries\n",
        "\n",
        "# Extract sequences (second element of the tuple)\n",
        "msa_sequences = msa[1]  # This contains only sequences, without headers\n",
        "\n",
        "# Convert to NumPy array ensuring sequences are split into individual characters\n",
        "msa_array = np.array([list(seq) for seq in msa_sequences])\n",
        "\n",
        "# Extract residues at positions 79 and 92 (0-based indexing)\n",
        "residues_79 = msa_array[:, 79]\n",
        "residues_92 = msa_array[:, 92]\n",
        "\n",
        "# Verify extraction\n",
        "print(\"First 10 residues at position 79:\", residues_79[:10])\n",
        "print(\"First 10 residues at position 92:\", residues_92[:10])\n",
        "\n",
        "\n",
        "# Count frequency of each amino acid at positions 79 and 92\n",
        "counts_79 = Counter(residues_79)\n",
        "counts_92 = Counter(residues_92)\n",
        "\n",
        "# Plot frequency of amino acids at positions 79 and 92\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Position 79\n",
        "axes[0].bar(counts_79.keys(), counts_79.values(), color=\"royalblue\")\n",
        "axes[0].set_title(\"Residue Frequency at Position 79\")\n",
        "axes[0].set_xlabel(\"Amino Acid\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[0].set_xticks(list(counts_79.keys()))  # Set x-ticks to amino acid letters\n",
        "axes[0].tick_params(axis='x', rotation=45)  # Rotate labels for readability\n",
        "\n",
        "# Position 92\n",
        "axes[1].bar(counts_92.keys(), counts_92.values(), color=\"crimson\")\n",
        "axes[1].set_title(\"Residue Frequency at Position 92\")\n",
        "axes[1].set_xlabel(\"Amino Acid\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "axes[1].set_xticks(list(counts_92.keys()))  # Set x-ticks to amino acid letters\n",
        "axes[1].tick_params(axis='x', rotation=45)  # Rotate labels for readability\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"First 10 residues at position 79:\", residues_79[:10])\n",
        "print(\"First 10 residues at position 92:\", residues_92[:10])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get indices of sequences where position 92 is 'I'\n",
        "i_at_92_indices = np.where(residues_92 == 'I')[0]\n",
        "\n",
        "# Print the first few sequences that match\n",
        "print(\"Sequences with I at position 92:\")\n",
        "for idx in i_at_92_indices[:5]:  # Show first 5 matching sequences\n",
        "    print(msa_sequences[idx])\n",
        "\n",
        "# If msa has sequence headers stored in msa[0] (modify if needed)\n",
        "headers = msa[0]  # Assuming msa[0] contains the sequence IDs\n",
        "\n",
        "# Print headers of sequences where position 92 is 'I'\n",
        "print(\"Matching sequence IDs:\")\n",
        "for idx in i_at_92_indices[:5]:  # Show first 5 matches\n",
        "    print(headers[idx])\n"
      ],
      "metadata": {
        "id": "x4xAScOo85xn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}